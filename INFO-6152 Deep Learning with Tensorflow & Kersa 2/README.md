# 📘 Deep Learning with TensorFlow and Keras 2 – Course Outline

| Week | Title                                                                 | Key Topics Covered                                                                                                                                                      |
|------|-----------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1    | 🧠 Intro to ANNs and Image Data Limitations                          | Overview of Artificial Neural Networks (ANNs) and their limitations in handling large image datasets                                                                    |
| 2    | 🧱 Fundamentals of CNNs                                               | CNN architecture, key components, and their applications in image processing                                                                                            |
| 3    | ⚙️ Working Principles of CNNs (Part 1)                                | Convolutional layers, operations, stride, padding, pooling, fully connected layers, forward/backpropagation, training, regularization techniques                         |
| 4    | ⚙️ Working Principles of CNNs (Part 2)                                | Real-world applications using TensorFlow/Keras, CNN models like ResNet, Inception, and step-by-step implementation                                                      |
| 5    | 🔁 Introduction to RNNs and Sequential Data                          | Feedforward NN limitations, RNN structure, unrolling, activation functions                                                                                              |
| 6    | 🔁 RNNs: Concepts & Implementation                                   | Capturing sequential dependencies, practical examples, strengths/weaknesses                                                                                             |
| 7    | ⏸️ Reading Week                                                      | No class                                                                                                                                                                |
| 8    | 🎼 Applications of RNNs                                              | Time series forecasting (finance, weather), music generation, video frame prediction, healthcare applications                                                           |
| 9    | 🔄 Advanced RNNs: LSTM & GRU (Part 1)                                | RNN limitations, LSTM intro and architecture, long-range dependency learning                                                                                           |
| 10   | 🔄 Advanced RNNs: LSTM & GRU (Part 2)                                | GRU intro, comparison with LSTM, BPTT training, optimization, real-world applications (text, speech, time series)                                                       |
| 11   | 👁️ Attention and Transformers (Part 1)                              | Attention mechanisms, types of attention, score functions, context vectors, Transformer intro, encoder-decoder, positional encoding                                     |
| 12   | 👁️ Attention and Transformers (Part 2)                              | Transformer deep dive: self-attention, multi-head attention, training, feed-forward networks, normalization, applications                                               |
| 13   | 🧪 Generative Adversarial Networks (GANs)                           | GAN intro, applications, architecture, training, loss design, variants: Conditional GANs, DCGANs, StyleGAN, etc.                                                        |
| 14   | 🛠️ Building & Evaluating GANs                                       | GANs for synthetic data, environment setup, architecture design, model implementation in TensorFlow/Keras                                                              |
| 15   | 🎤 Final Project Presentations                                       | Student presentations on final projects                                                                                                                                |

## 🧾 Marking Scheme

| Component           | Weight  |
|--------------------|---------|
| In-Class Activities (4 total) | 20%     |
| Quizzes (3 required + 1 optional) | 30%     |
| Final Project                 | 30%     |
| Final Presentation + Q&A     | 20%     |

### 📚 Quizzes
- **Quiz 1 (10%)** – Based on Weeks 1–3  
- **Quiz 2 (10%)** – Based on Weeks 4–7  
- **Quiz 3 (10%)** – Based on Weeks 9–12  
- **Optional Quiz 4 (10%)** – Based on Weeks 13–14  

### 🧑‍🏫 In-Class Activities
- **Activity 1 (5%)** – Weeks 1–2  
- **Activity 2 (5%)** – Weeks 4–6  
- **Activity 3 (5%)** – Weeks 8–10  
- **Activity 4 (5%)** – Weeks 11–12  

---

## 🚀 Final Project – 30%

Students will design, implement, and evaluate an end-to-end deep learning solution using **TensorFlow and Keras**, selecting one or more of the following architectures: **CNN, LSTM, GRU, Transformer, or GAN**.

Final deliverables must include:

- A clear, well-structured **written report** explaining:
  - Problem statement and objective
  - Data processing and model design decisions
  - Coding logic and implementation flow
  - Observations and lessons learned

- **Well-documented source code** answering all relevant coding tasks and questions provided

- A **Results Section** clearly detailing:
  - Evaluation metrics and outcomes
  - Visualizations (if applicable)
  - Interpretations of performance

- A concise **oral presentation and Q&A session** during the final week (Week 15)

---

This course explores advanced deep learning concepts through hands-on implementation using TensorFlow and Keras. Students will gain experience with CNNs, RNNs (including LSTM and GRU), Transformer models, and GANs, while solving real-world problems and presenting their solutions.