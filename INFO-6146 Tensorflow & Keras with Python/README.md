# üìò Tensorflow & Keras with Python ‚Äì Course Outline
| Week | Title                                                        | Key Topics Covered | Interactive Link |
|------|--------------------------------------------------------------|--------------------|------------------|
| 1    | üîç Deep Learning Fundamentals I                              | Overview of AI, ML, and DL; ML challenges; learning algorithms (supervised, unsupervised, reinforcement); feature engineering limitations; tensors and data representation; optimization (gradient descent); overfitting and regularization | [Deep Learning 101 (Google)](https://developers.google.com/machine-learning/crash-course)<br><br>[Tensor Basics Playground (TensorFlow)](https://www.tensorflow.org/guide/tensor) |
| 2    | üîç Deep Learning Fundamentals II                             | History and key milestones of deep learning; advantages over traditional ML; fundamentals of deep architectures (neurons, layers, activation functions, MLP); introduction to ANNs, CNNs, and RNNs | [Neural Network Playground (TensorFlow)](https://playground.tensorflow.org/)<br><br>[Deep Learning Timeline (MIT)](http://introtodeeplearning.com/) |
| 3    | üìä Deep Learning vs. ML: Real-World Use and Tools | Key differences between ML and DL (data scale, complexity, compute needs); strengths and limitations of DL (end-to-end learning, scalability, unstructured data handling); practical decision-making for model selection; real-world use cases (vision, NLP, finance, healthcare, autonomous systems); DL failure scenarios; comparison of key libraries (scikit-learn, Keras, PyTorch, Hugging Face, TensorFlow Hub, ONNX);| [ML vs DL Comparison Interactive](https://www.analyticsvidhya.com/blog/2020/11/difference-between-machine-learning-and-deep-learning/)<br><br>[Hugging Face Model Explorer](https://huggingface.co/models) |
| 4    | ‚öôÔ∏è Framework Setup and TensorFlow Playground Demo           | Overview of Keras and TensorFlow; interactive demo of ANNs using TensorFlow Playground: learning rate, activation, regularization, architecture depth; installing and configuring TensorFlow and Keras | [TensorFlow Playground](https://playground.tensorflow.org/)<br><br>[Keras Setup Guide](https://keras.io/getting_started/) |
| 5    | ‚öôÔ∏è Deep Learning Environment and Keras API                   | Basics of tensors, operations, and computation graphs; using tf.data and TFDS for efficient data pipelines; Sequential vs. Functional API; compiling, training, evaluating models; setting up training strategies on CPU, GPU, TPU; visualizing with TensorBoard; model serialization; deployment options | [TensorFlow Data API Guide](https://www.tensorflow.org/guide/data)<br><br>[TensorBoard Demo (TensorFlow)](https://www.tensorflow.org/tensorboard) |
| 6    | üìä Data Loading, EDA & Preprocessing                         | Loading datasets from CSV, Excel, JSON, APIs, and archives; data inspection using pandas and NumPy; visualizing distributions and relationships using matplotlib and seaborn; feature engineering (derived columns, binning, outlier handling); encoding strategies (one-hot, ordinal); scaling and transforming features (standardization, normalization, power/log transforms); data augmentation for images, text, and imbalanced data; preparing TensorFlow-compatible datasets using tf.data API (map, batch, shuffle, cache, prefetch); best practices for preprocessing pipelines in deep learning workflows. | [Pandas Profiling Demo](https://pandas-profiling.ydata.ai/docs/master/rtd/index.html)<br><br>[Albumentations Image Augmentation Playground](https://albumentations.ai/) |
| 7    | üìä Modeling Pipelines & Transfer Learning                    | Handling imbalanced data; train-test split and cross-validation; building Keras modeling pipelines; hyperparameter tuning with GridSearchCV; supervised models for tabular and image data; transfer learning with pretrained CNNs | [TensorFlow Transfer Learning Tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning)<br><br>[Sklearn Model Evaluation Demo](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html) |
| 8    | üîß Supervised Learning with Keras                            | Classification and regression with MLPs using Sequential API; activation functions (ReLU, softmax, sigmoid); loss functions (MSE, cross-entropy); evaluation metrics (accuracy, MSE, RMSE); CNN image classification pipeline; model tuning and visualization with TensorBoard; Sequential vs. Functional API | [Keras Sequential API Docs](https://keras.io/guides/sequential_model/)<br><br>[TensorBoard Scalars & Graphs Demo](https://www.tensorflow.org/tensorboard/scalars_and_graphs) |
| 9    | üß© Unsupervised Learning with Autoencoders                   | Clustering, dimensionality reduction, and anomaly detection; difference from supervised learning; vanilla, deep, convolutional, and regularized autoencoders; training for denoising and reconstruction; anomaly detection using AEs and VAEs (ECG dataset) | [Autoencoder Visualizer (ML4A)](https://ml4a.github.io/guides/Autoencoder/)<br><br>[ECG Anomaly Detection Demo (TensorFlow)](https://www.tensorflow.org/tutorials/structured_data/time_series) |
| 10   | üß© VAEs and Clustering with Neural Networks                  | Variational Autoencoders: probabilistic latent spaces, reparameterization trick, reconstruction + KL loss; feature extraction; clustering with encoder + K-Means/DBSCAN; practical implementation and visualization in Keras | [VAE Explanation (Jalammar)](https://jalammar.github.io/illustrated-vae/)<br><br>[VAE Implementation (Keras)](https://keras.io/examples/generative/vae/) |
| 11   | ‚è≥ Sequence Modeling with HMMs                               | HMM fundamentals: Markov property, hidden states, observable outputs; HMM architecture (transition, emission, initial probabilities); Forward, Backward, Viterbi, Forward-Backward algorithms; supervised vs. unsupervised training (Baum-Welch, EM); model selection (likelihood, AIC, BIC) | [HMM Demo (Victor Lavrenko)](http://homepages.inf.ed.ac.uk/vlavrenk/teaching/nn/hmm_viz.htm)<br><br>[HMM Animation (YouTube)](https://www.youtube.com/watch?v=QqLHl3c_f2g) |
| 12   | üõ†Ô∏è HMM Implementation, Inference & Keras Recap              | Implementing HMMs using Python/hmmlearn; simulated weather modeling; inference with Viterbi; evaluating and visualizing HMMs; initialization/convergence issues; summary of Keras APIs (compile, fit, evaluate, predict); model configuration best practices | [hmmlearn Documentation](https://hmmlearn.readthedocs.io/en/latest/)<br><br>[Viterbi Path Demo (MIT)](https://people.csail.mit.edu/trevor/hmm/) |
| 13   | üé§ Final Project Presentations                               | Student presentations on final projects | |
| 14   | üß™ Final Exam                                                | theory and practical | |


## üßæ Marking Scheme
| Component         | Weight |
|-------------------|--------|
| In-Class Activity (5 total) | 20%    |
| Quizzes (4 total) | 20%    |
| Final Project     | 30%    |
| Final Exam        | 30%    |

This course offers a hands-on and applied journey into deep learning using TensorFlow and Keras. Students will build and tune real models, extract and preprocess open data, and implement both supervised and unsupervised learning. The course culminates with advanced sequence modeling using HMMs and a final project demonstrating technical, analytical, and communication skills.
