# ğŸ“˜ Applied Machine Learning Optimization â€“ Course Outline

| Session | Title                                               | Key Topics Covered                                                                 |
|---------|-----------------------------------------------------|------------------------------------------------------------------------------------|
| 1       | [ğŸ§­ Introduction to Optimization in Machine Learning](https://github.com/mnoorchenar/Courses/tree/main/INFO-6154%20Machine%20Learning%20Optimization%20Strategies/%F0%9F%A7%AD%20Introduction%20to%20Optimization%20in%20Machine%20Learning) | Role of optimization in ML, loss functions, practical failures, project framing   |
| 2       | ğŸ§® Gradient Descent and Its Variants                | GD, SGD, mini-batch, momentum, when and why to use each                           |
| 3       | âš™ï¸ Optimizers in Practice                           | Adam, RMSProp, AdamW; learning rate tuning; scheduler types (step, cosine, etc.)  |
| 4       | ğŸ§ª Hyperparameter Tuning Basics                     | Search space design, grid search, random search, validation strategies            |
| 5       | ğŸ” Bayesian Optimization with Tools                 | Intuition (no math), Optuna or Hyperopt, real-world tuning workflows              |
| 6       | ğŸ›¡ï¸ Regularization Techniques                        | L1/L2, dropout, early stopping, practical overfitting control                     |
| 7       | ğŸ§  Neural Network Optimization & Stability          | Initialization, batch norm, gradient clipping, residual connections               |
| 8       | ğŸ“ Model Evaluation and Metric Optimization         | Metric vs. loss, F1, AUC, RMSE, business-metric alignment                         |
| 9       | ğŸ“ˆ Time Series Optimization Essentials              | Windowing, target shifting, rolling validation, time-aware tuning                 |
| 10      | ğŸ” Explainability and Optimization Decisions        | SHAP, LIME, tuning with feature importance, balancing performance vs. transparency|
| 11      | ğŸ§° Debugging & Visualizing Optimization             | Loss curves, gradient diagnostics, TensorBoard, Weights & Biases                  |
| 12      | ğŸš€ Capstone: End-to-End Optimization Project        | Tuning, evaluating, and explaining a real model; wrap-up and key takeaways        |
