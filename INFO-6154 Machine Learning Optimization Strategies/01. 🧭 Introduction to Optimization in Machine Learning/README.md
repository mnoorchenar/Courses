# ðŸ“š Further Reading â€“ Introduction to Optimization in Machine Learning

This section supports **Session 1: Introduction to Optimization in ML**, exploring what optimization is, its role in machine learning, and the fundamentals behind training models.

---

## ðŸ“˜ Core Learning Resources

These interactive resources from Googleâ€™s ML Crash Course offer a hands-on introduction to optimization concepts using linear regression:

- ðŸ”¢ [Linear Regression Overview](https://developers.google.com/machine-learning/crash-course/linear-regression)  
  Understand how models learn from data through parameter adjustment.

- ðŸ“‰ [Loss Function](https://developers.google.com/machine-learning/crash-course/linear-regression/loss)  
  Explore how loss functions measure prediction error and guide optimization.

- âš™ï¸ [Tune Model Parameters (Interactive)](https://developers.google.com/machine-learning/crash-course/linear-regression/parameters-exercise)  
  Try manually adjusting weights and biases to minimize loss in real time.

---

## ðŸ§  Bonus Insight

> *"Optimization is not just a computational step â€” it's the core logic that enables models to learn from data. Choosing the right loss function and optimizer is as important as the model architecture itself."*

---

## ðŸŽ¨ Optional â€“ Visualization-Rich Resource

If you're a visual learner, this site is highly recommended:

- ðŸ“Š [Distill.pub: Visualizing Gradient Descent](https://distill.pub/2017/momentum/)  
  Beautiful, interactive explanations of optimization techniques like gradient descent and momentum.
